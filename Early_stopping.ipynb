{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOkVYpAC1eOemzLZfzhlYcK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"kZOOT_FDeHwn"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import tensorflow.keras\n","from tensorflow.keras.datasets import cifar10\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Flatten\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D\n","from tensorflow.keras.callbacks import TensorBoard\n","from time import time\n","import tensorflow as tf\n","import os"],"metadata":{"id":"6mIwecbIeMkG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%load_ext tensorboard"],"metadata":{"id":"tamYwvfCeOBN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#early stopping\n"," # This callback will stop the training when there is no improvement in\n"," # the loss for three consecutive epochs.\n","early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3) #>val_loss\n","\n","#Create a checkpoint\n","logdir = os.path.join(\"/content/drive/MyDrive/DEEP_LOG/logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n","checkpoint_filepath = logdir + '/checkpoint/'\n","print(checkpoint_filepath)\n","\n","\n","model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_filepath,\n","    save_weights_only=True,\n","    monitor='val_accuracy',\n","    mode='max',\n","    save_best_only=True)\n","\n","\n","\n","#scheduler Function\n","def lr_schedule(epoch):\n","  \"\"\"\n","  Returns a custom learning rate that decreases as epochs progress.\n","  \"\"\"\n","  learning_rate = 0.2\n","  if epoch > 10:\n","    learning_rate = 0.02\n","  if epoch > 20:\n","    learning_rate = 0.01\n","  if epoch > 50:\n","    learning_rate = 0.005\n","  \n","  tf.summary.scalar('learning rate', data=learning_rate, step=epoch)\n","  return learning_rate"],"metadata":{"id":"_EnReIMtePld"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#initializing LearningRateScheduler\n","callback = tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n","\n","import datetime\n","#to see learning rate\n","logdir = os.path.join(\"/content/drive/MyDrive/DEEP_LOG/logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n","file_writer = tf.summary.create_file_writer(logdir + \"/metrics\")\n","file_writer.set_as_default()\n","\n","# Model configuration\n","img_width, img_height = 32, 32\n","batch_size = 250\n","no_epochs = 40\n","no_classes = 10\n","validation_split = 0.2\n","verbosity = 1"],"metadata":{"id":"Ljzmjhg0eRlJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Load CIFAR10 dataset\n","(input_train, target_train), (input_test, target_test) = cifar10.load_data()\n","\n","# Visualize CIFAR10 dataset\n","import matplotlib.pyplot as plt\n","classes = {\n","  0: 'airplane',\n","  1: 'automobile',\n","  2: 'bird',\n","  3: 'cat',\n","  4: 'deer',\n","  5: 'dog',\n","  6: 'frog',\n","  7: 'horse',\n","  8: 'ship',\n","  9: 'truck'\n","}\n","fig, axes = plt.subplots(2,5, sharex=True)\n","axes[0,0].imshow(input_train[0])\n","axes[0,1].imshow(input_train[1])\n","axes[0,2].imshow(input_train[2])\n","axes[0,3].imshow(input_train[3])\n","axes[0,4].imshow(input_train[4])\n","axes[1,0].imshow(input_train[5])\n","axes[1,1].imshow(input_train[6])\n","axes[1,2].imshow(input_train[7])\n","axes[1,3].imshow(input_train[8])\n","axes[1,4].imshow(input_train[9])\n","axes[0,0].set_title(classes[target_train[0][0]])\n","axes[0,1].set_title(classes[target_train[1][0]])\n","axes[0,2].set_title(classes[target_train[2][0]])\n","axes[0,3].set_title(classes[target_train[3][0]])\n","axes[0,4].set_title(classes[target_train[4][0]])\n","axes[1,0].set_title(classes[target_train[5][0]])\n","axes[1,1].set_title(classes[target_train[6][0]])\n","axes[1,2].set_title(classes[target_train[7][0]])\n","axes[1,3].set_title(classes[target_train[8][0]])\n","axes[1,4].set_title(classes[target_train[9][0]])\n","axes[0,0].set_axis_off()\n","axes[0,1].set_axis_off()\n","axes[0,2].set_axis_off()\n","axes[0,3].set_axis_off()\n","axes[0,4].set_axis_off()\n","axes[1,0].set_axis_off()\n","axes[1,1].set_axis_off()\n","axes[1,2].set_axis_off()\n","axes[1,3].set_axis_off()\n","axes[1,4].set_axis_off()\n","plt.show()"],"metadata":{"id":"JCAFnjhmeTfs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_shape = (img_width, img_height, 3)\n","\n","# Parse numbers as floats\n","input_train = input_train.astype('float32')\n","input_test = input_test.astype('float32')\n","\n","# Convert them into black or white: [0, 1].\n","input_train = input_train / 255\n","input_test = input_test / 255\n","\n","# Convert target vectors to categorical targets\n","target_train = tensorflow.keras.utils.to_categorical(target_train, no_classes)\n","target_test = tensorflow.keras.utils.to_categorical(target_test, no_classes)"],"metadata":{"id":"8PPgddSxeVgt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Sequential()\n","model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","model.add(Flatten())\n","model.add(Dense(256, activation='relu'))\n","model.add(Dense(no_classes, activation='softmax'))"],"metadata":{"id":"cNP0DaKReXa2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def Train():\n","  model.compile(loss=tensorflow.keras.losses.categorical_crossentropy,\n","                optimizer=tensorflow.keras.optimizers.Adam(),\n","                metrics=['accuracy'])\n","  \n","  # Define Tensorboard as a Keras callback\n","  tensorboard = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n","\n","  keras_callbacks = [\n","  tensorboard , callback , model_checkpoint_callback , early_stopping\n","]\n","\n","  model.fit(input_train, target_train,\n","            batch_size=batch_size,\n","            epochs=no_epochs,\n","            verbose=verbosity,\n","            validation_split=validation_split,\n","\n","            callbacks=keras_callbacks)\n","\n","  # Generate generalization metrics\n","  score = model.evaluate(input_test, target_test, verbose=0)\n","  print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')\n","\n","\n","Train()"],"metadata":{"id":"AiviSqSQeZLs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%tensorboard --logdir \"/content/drive/MyDrive/DEEP_LOG/logs\""],"metadata":{"id":"2ePGO1BAea9t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.load_weights(checkpoint_filepath)"],"metadata":{"id":"0eOUSBYreeam"},"execution_count":null,"outputs":[]}]}